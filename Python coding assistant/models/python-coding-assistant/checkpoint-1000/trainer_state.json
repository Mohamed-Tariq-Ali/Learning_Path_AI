{
  "best_metric": 0.6078282594680786,
  "best_model_checkpoint": "./python-coding-assistant/checkpoint-1000",
  "epoch": 1.774622892635315,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.044365572315882874,
      "grad_norm": 0.3336404263973236,
      "learning_rate": 0.0001,
      "loss": 0.9175,
      "step": 25
    },
    {
      "epoch": 0.08873114463176575,
      "grad_norm": 0.3563392758369446,
      "learning_rate": 0.0002,
      "loss": 0.6858,
      "step": 50
    },
    {
      "epoch": 0.13309671694764863,
      "grad_norm": 0.3548189103603363,
      "learning_rate": 0.0001997337237739192,
      "loss": 0.6932,
      "step": 75
    },
    {
      "epoch": 0.1774622892635315,
      "grad_norm": 0.320965439081192,
      "learning_rate": 0.0001989363131562483,
      "loss": 0.6769,
      "step": 100
    },
    {
      "epoch": 0.22182786157941436,
      "grad_norm": 0.27730879187583923,
      "learning_rate": 0.00019761201477678549,
      "loss": 0.6215,
      "step": 125
    },
    {
      "epoch": 0.26619343389529726,
      "grad_norm": 0.3014712631702423,
      "learning_rate": 0.00019576788121902457,
      "loss": 0.6177,
      "step": 150
    },
    {
      "epoch": 0.3105590062111801,
      "grad_norm": 0.29921194911003113,
      "learning_rate": 0.00019341373346144848,
      "loss": 0.6912,
      "step": 175
    },
    {
      "epoch": 0.354924578527063,
      "grad_norm": 0.3514650762081146,
      "learning_rate": 0.0001905621085756678,
      "loss": 0.5971,
      "step": 200
    },
    {
      "epoch": 0.3992901508429459,
      "grad_norm": 0.3137285113334656,
      "learning_rate": 0.00018722819295993807,
      "loss": 0.6671,
      "step": 225
    },
    {
      "epoch": 0.44365572315882873,
      "grad_norm": 0.33551937341690063,
      "learning_rate": 0.00018342974146362396,
      "loss": 0.5988,
      "step": 250
    },
    {
      "epoch": 0.4880212954747116,
      "grad_norm": 0.35572579503059387,
      "learning_rate": 0.00017918698283331318,
      "loss": 0.6197,
      "step": 275
    },
    {
      "epoch": 0.5323868677905945,
      "grad_norm": 0.31086134910583496,
      "learning_rate": 0.00017452251198413083,
      "loss": 0.6635,
      "step": 300
    },
    {
      "epoch": 0.5767524401064774,
      "grad_norm": 0.4479053318500519,
      "learning_rate": 0.00016946116966996456,
      "loss": 0.6352,
      "step": 325
    },
    {
      "epoch": 0.6211180124223602,
      "grad_norm": 0.3484949767589569,
      "learning_rate": 0.00016402991019342074,
      "loss": 0.6719,
      "step": 350
    },
    {
      "epoch": 0.6654835847382431,
      "grad_norm": 0.34100469946861267,
      "learning_rate": 0.00015825765786002497,
      "loss": 0.6191,
      "step": 375
    },
    {
      "epoch": 0.709849157054126,
      "grad_norm": 0.389242023229599,
      "learning_rate": 0.0001521751529411237,
      "loss": 0.6435,
      "step": 400
    },
    {
      "epoch": 0.7542147293700089,
      "grad_norm": 0.2909966707229614,
      "learning_rate": 0.00014581478796581548,
      "loss": 0.5738,
      "step": 425
    },
    {
      "epoch": 0.7985803016858918,
      "grad_norm": 0.3239210546016693,
      "learning_rate": 0.00013921043521374258,
      "loss": 0.6476,
      "step": 450
    },
    {
      "epoch": 0.8429458740017747,
      "grad_norm": 0.562235951423645,
      "learning_rate": 0.0001323972663274357,
      "loss": 0.6033,
      "step": 475
    },
    {
      "epoch": 0.8873114463176575,
      "grad_norm": 0.4070856273174286,
      "learning_rate": 0.00012541156500486873,
      "loss": 0.6492,
      "step": 500
    },
    {
      "epoch": 0.8873114463176575,
      "eval_loss": 0.6122503280639648,
      "eval_runtime": 57.109,
      "eval_samples_per_second": 8.773,
      "eval_steps_per_second": 2.206,
      "step": 500
    },
    {
      "epoch": 0.9316770186335404,
      "grad_norm": 0.3649682104587555,
      "learning_rate": 0.00011829053376973567,
      "loss": 0.6175,
      "step": 525
    },
    {
      "epoch": 0.9760425909494232,
      "grad_norm": 0.39547982811927795,
      "learning_rate": 0.00011107209584849845,
      "loss": 0.6164,
      "step": 550
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 0.2549748122692108,
      "learning_rate": 0.00010379469320931435,
      "loss": 0.6003,
      "step": 575
    },
    {
      "epoch": 1.064773735581189,
      "grad_norm": 0.30682724714279175,
      "learning_rate": 9.649708183839203e-05,
      "loss": 0.6155,
      "step": 600
    },
    {
      "epoch": 1.109139307897072,
      "grad_norm": 0.3872968852519989,
      "learning_rate": 8.92181253440366e-05,
      "loss": 0.6475,
      "step": 625
    },
    {
      "epoch": 1.1535048802129548,
      "grad_norm": 0.31035691499710083,
      "learning_rate": 8.199658798755047e-05,
      "loss": 0.6387,
      "step": 650
    },
    {
      "epoch": 1.1978704525288375,
      "grad_norm": 0.37613871693611145,
      "learning_rate": 7.487092824320944e-05,
      "loss": 0.6094,
      "step": 675
    },
    {
      "epoch": 1.2422360248447206,
      "grad_norm": 0.3191857635974884,
      "learning_rate": 6.787909398671459e-05,
      "loss": 0.6135,
      "step": 700
    },
    {
      "epoch": 1.2866015971606033,
      "grad_norm": 0.49680599570274353,
      "learning_rate": 6.105832040285003e-05,
      "loss": 0.5964,
      "step": 725
    },
    {
      "epoch": 1.3309671694764862,
      "grad_norm": 0.32709476351737976,
      "learning_rate": 5.444493168859304e-05,
      "loss": 0.5862,
      "step": 750
    },
    {
      "epoch": 1.375332741792369,
      "grad_norm": 0.36239516735076904,
      "learning_rate": 4.8074147607712316e-05,
      "loss": 0.6149,
      "step": 775
    },
    {
      "epoch": 1.419698314108252,
      "grad_norm": 0.46353501081466675,
      "learning_rate": 4.1979895927052584e-05,
      "loss": 0.5821,
      "step": 800
    },
    {
      "epoch": 1.4640638864241349,
      "grad_norm": 0.35967597365379333,
      "learning_rate": 3.619463173338e-05,
      "loss": 0.5913,
      "step": 825
    },
    {
      "epoch": 1.5084294587400178,
      "grad_norm": 0.3262155055999756,
      "learning_rate": 3.074916459302211e-05,
      "loss": 0.5879,
      "step": 850
    },
    {
      "epoch": 1.5527950310559007,
      "grad_norm": 0.2935030162334442,
      "learning_rate": 2.5672494474766428e-05,
      "loss": 0.6252,
      "step": 875
    },
    {
      "epoch": 1.5971606033717833,
      "grad_norm": 0.3881165683269501,
      "learning_rate": 2.0991657309815982e-05,
      "loss": 0.5966,
      "step": 900
    },
    {
      "epoch": 1.6415261756876665,
      "grad_norm": 0.3283601701259613,
      "learning_rate": 1.6731581011274356e-05,
      "loss": 0.6578,
      "step": 925
    },
    {
      "epoch": 1.6858917480035491,
      "grad_norm": 0.3011572062969208,
      "learning_rate": 1.2914952719933371e-05,
      "loss": 0.6337,
      "step": 950
    },
    {
      "epoch": 1.7302573203194322,
      "grad_norm": 0.31707093119621277,
      "learning_rate": 9.562097983348505e-06,
      "loss": 0.5863,
      "step": 975
    },
    {
      "epoch": 1.774622892635315,
      "grad_norm": 0.32686442136764526,
      "learning_rate": 6.690872511636814e-06,
      "loss": 0.5743,
      "step": 1000
    },
    {
      "epoch": 1.774622892635315,
      "eval_loss": 0.6078282594680786,
      "eval_runtime": 57.0896,
      "eval_samples_per_second": 8.776,
      "eval_steps_per_second": 2.207,
      "step": 1000
    }
  ],
  "logging_steps": 25,
  "max_steps": 1126,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.50284203214848e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
